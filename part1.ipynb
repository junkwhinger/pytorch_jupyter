{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝: 손글씨 인식 웹앱 만들기\n",
    "## part 1. 딥러닝 모델 학습하기\n",
    "\n",
    "\n",
    "### 1. 손글씨 데이터셋 살펴보기\n",
    "이번 넥슨토크에서 사용할 손글씨 데이터셋은 MNIST라는 데이터셋으로, 딥러닝 분야의 유명 석학인 얀 르쿤(Yann Lecun)와 그 동료들이 공개한 데이터셋입니다.\n",
    " \n",
    "| ![Yann Lecun](img/yann_lecun.jpeg) |\n",
    "|:--:|\n",
    "|*딥러닝의 대가 얀 르쿤*|\n",
    "\n",
    "MNIST 데이터셋은 0~9까지의 이미지와 숫자(정답)로, Training 데이터셋에는 6만개, Test 데이터셋은 1만개의 데이터로 구성되어 있습니다.\n",
    "\n",
    "딥러닝 오픈소스 라이브러리인 PyTorch에는 MNIST를 포함한 여러 데이터셋이 들어있습니다. 아래 코드를 실행해서 MNIST 데이터셋을 가져와봅시다 +_+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 필요한 라이브러리를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #파이토치\n",
    "import torchvision.datasets as vdatasets #데이터셋 모음\n",
    "import torchvision.utils as vutils #유틸리티함수\n",
    "import torchvision.transforms as vtransform #변환함수\n",
    "\n",
    "import numpy as np #수치연산\n",
    "import matplotlib.pyplot as plt #시각화\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch에서 데이터셋을 내려받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 데이터셋은 PIL 이미지인 관계로,\n",
    "# 각 이미지의 크기를 가로세로 28x28로 맞춰주고\n",
    "# 모델이 이해할 수 있도록 숫자로 바꿔주는 함수를 먼저 정의합니다.\n",
    "# 이를 바로 다음 셀에서 파라미터로 넘겨줍니다.\n",
    "transform = vtransform.Compose(\n",
    "    [vtransform.Resize((28,28))\n",
    "    ,vtransform.ToTensor()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training / test 데이터셋을 가져옵니다.\n",
    "# 딥러닝을 할때는 데이터를 batch로 잘게 쪼개서 학습합니다.\n",
    "# 배치를 편리하게 가져올 수 있도록 DataLoader에 넣어줍니다.\n",
    "# 여기서는 64개씩 가져오도록 설정해두었습니다.\n",
    "train_dataset = vdatasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n",
    "test_dataset = vdatasets.MNIST(root=\"data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떻게 생겼는지 살펴볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋은 이미지와 그 답(숫자)로 되어있습니다.\n",
    "\n",
    "Pytorch에서는 데이터가 `Tensor`안에 저장됩니다. `Tensor`는 여러 차원으로 구성된 숫자 데이터라고 보시면 됩니다. `Tensor`의 모양을 살펴보려면 `.size()`를 실행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 64 = Batch의 크기. 위에서 DataLoader를 설정할때 넣은 64입니다.\n",
    "- 1 = 컬러채널의 수. 흑백이미지이므로 채널이 1입니다. RGB 이미지는 3이죠.\n",
    "- 28 = 이미지의 세로 크기입니다.\n",
    "- 28 = 이미지의 가로 크기입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 어떻게 생겼는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # Tensor를 numpy array로 바꿔줍니다.\n",
    "    img = img.numpy()\n",
    "    # matplotlib에서 인식할 수 있도록 컬러채널을 끝으로 옮깁니다.\n",
    "    transposed_img = np.transpose(img, (1, 2, 0))\n",
    "    \n",
    "    # 시각화합니다.\n",
    "    plt.imshow(np.squeeze(transposed_img))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#64개의 이미지를 그리드에 넣어 뿌려봅니다.\n",
    "#옆에 사람과 보시는 이미지가 다릅니다.\n",
    "#그 이유는 DataLoader에서 Shuffle=True를 설정했기 때문이죠.\n",
    "imshow(vutils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해봅시다!\n",
    "1) 이미지에 대응하는 숫자(정답)은 어떤 형태일까요? 숫자가 저장된 텐서를 찍어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 트레이닝 데이터와 테스트 데이터는 각각 몇개의 데이터포인트를 가지고 있을까요? 찍어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dataset.train_labels.size())\n",
    "# print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 모델 설계하기\n",
    "\n",
    "이제 딥러닝 모델을 만들어볼텐데요, 먼저 가장 단순한 '히든 레이어가 없는' 신경망 모델을 만들어봅시다.\n",
    "\n",
    "#### 필요한 라이브러리를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만들 모델의 명세는 다음과 같습니다.\n",
    "- 입력 레이어: 784개 뉴런\n",
    "- 출력 레이어: 10개 뉴런 (0~9)\n",
    "\n",
    "0부터 9까지 총 10개의 가짓수니까 출력 레이어의 뉴런 수가 10인건 알겠는데, 왜 입력 레이어의 뉴런은 784개일까요?\n",
    "\n",
    "그 이유는 우리가 가진 개별 이미지의 크기가 28x28이기 때문입니다.\n",
    "\n",
    "지금 우리가 만들려는 모델은 가장 단순한 모델로, 28x28 이미지를 한줄로 길게 늘어뜨릴 겁니다. 그러면 28x28=784로, 하나의 이미지당 784개의 픽셀값을 얻게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 이미지 1개의 차원 (1 x 28 x 28)\n",
    "images[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 배치(64개 이미지)는 이렇게 생겼었죠.\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.view(원하는 차원)`를 사용하면 텐서를 원하는 차원으로 변형할 수 있습니다. `-1`을 넘기는 차원은 알아서 계산이 됩니다. (배치, 784) 차원으로 바꿔봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.view(-1, 784).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple_DNN 구현하기\n",
    "PyTorch에서 모델을 구현하는 방법은 여럿이 있지만, 클래스를 사용하면 쉽게 모델을 구현할 수 있습니다.\n",
    "\n",
    "보통 `__init__`과 `forward` 함수를 구현합니다.\n",
    "- init: 딥러닝 모델에서 사용할 여러 레이어를 정의합니다.\n",
    "- foward: 실제 연산이 이루어지는 부분으로 정의한 레이어를 사용하여 최종 결과를 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleDNN, self).__init__()\n",
    "        # 784 => 10\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "         \n",
    "    def forward(self, inputs):\n",
    "        # 64x1x28x28 => 64x784\n",
    "        x = inputs.view(-1, 784)\n",
    "         \n",
    "        # 1st fully connected\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과가 어떻게 떨어지는지 확인해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스를 하나 만듭니다.\n",
    "model = SimpleDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model을 함수처럼 사용하면 .forward()함수가 실행됩니다.\n",
    "result = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력한 64개의 이미지들에 대한 0-9까지의 확률값이 반환되었습니다.\n",
    "result.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 결과를 볼까요?\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(0, 10), result[0].data.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 확률이 높게 나온 것은... \n",
    "# argmax는 가장 높은 값을 지닌 인덱스를 찾아줍니다.\n",
    "result[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하지만 실제 이미지는...\n",
    "imshow(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습이 전혀되지 않은 상태이니 맞출 수 없는건 당연합니다.  \n",
    "설계한 모델을 어떻게 학습할지 배워봅시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해봅시다!\n",
    "\n",
    "이번에는 조금 더 복잡한 모델을 만들어봅시다.\n",
    "- 입력 레이어: 뉴런 784개\n",
    "- 히든 레이어1: 뉴런 256개\n",
    "- 히든 레이어2: 뉴런 32개\n",
    "- 출력 레이어: 뉴런 10개\n",
    "\n",
    "각 히든 레이어 다음에는 relu 액티베이션 함수를 사용합니다.\n",
    "forward 함수에서 x = self.relu(x)와 같은 형태로 설정합니다.\n",
    "\n",
    "아래 DNN 클래스에서 히든레이어 2 부분을 채워넣어보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        \n",
    "        #TODO\n",
    "        self.fc2 = None\n",
    "        \n",
    "        self.last_layer = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "         \n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view(-1, 784)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #TODO\n",
    "        x = None\n",
    "        \n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에러가 나지 않고 정상적으로 (64, 10) 크기의 텐서가 출력되나요?\n",
    "try:\n",
    "    result = model(images)\n",
    "    print(result.size())\n",
    "except:\n",
    "    print(\"error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 설계하기\n",
    "\n",
    "### Loss\n",
    "출력한 값에 대해서 실제 값과의 오차를 계산해야합니다.\n",
    "오차는 CrossEntropyLoss에 예측값과 실제값을 넘겨서 구하는데,\n",
    "PyTorch에서는 다음과 같이 어떤 오차함수를 쓸지만 정하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Loss를 구한다음, Loss를 사용해서 파라미터를 업데이트해야 합니다.\n",
    "PyTorch에서는 optim을 사용해서 모델 파라미터를 업데이트하는 여러 옵티마이징 함수를 사용할 수 있습니다. 가장 널리 쓰이는 함수 중 하나인 Adam 옵티마이저를 사용해봅시다!\n",
    "\n",
    "옵티마이저 함수에는 튜닝할 모델의 파라미터와 learning rate를 파라미터로 넘겨줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Epoch과 batch를 돌면서 학습을 진행할 것인데요, 그 과정에서 학습이 잘 되고 있는지를 판단해야 할 기준이 필요합니다. 정확한 분류모델은 출력값과 예측값의 오차(loss)가 작은 모델이겠죠? 그리고 모델이 최종적으로 출력하는 숫자와 정답 숫자가 얼마나 같은지를 accuracy를 통해 측정해봅시다.\n",
    "\n",
    "먼저 학습 도중 발생하는 loss와 accuracy를 편리하게 저장하기 위해 다음과 같은 정보 저장용 클래스를 하나 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기\n",
    "\n",
    "먼저 데이터 배치를 처음부터 끝까지 돌면서 학습하는 함수를 구현해봅시다.\n",
    "\n",
    "1. loss, accuracy 메트릭을 정의합니다.\n",
    "2. 모델을 학습 모드로 설정합니다.\n",
    "3. for loop을 사용해 train_dataloader에서 1개 배치를 가져옵니다.\n",
    "  - optimizer의 미분값을 초기화합니다.\n",
    "  - 이미지를 모델에 넣어 예측값을 출력합니다.\n",
    "  - 예측값과 실제값의 loss를 구합니다.\n",
    "  - loss를 저장합니다.\n",
    "  - accuracy를 구하고 accuracy를 저장합니다.\n",
    "  - 모델 파라미터에 대한 loss의 미분값을 계산합니다.\n",
    "  - optimizer를 사용해 모델 파라미터를 업데이트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, model, loss_function, optimizer, epoch):\n",
    "    #loss, accuracy 메트릭을 정의합니다.\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    \n",
    "    #모델을 학습 모드로 설정합니다.\n",
    "    model.train()\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        #train_dataloader에서 1개 배치를 가져옵니다.\n",
    "        #.to(device)로 cpu, gpu 환경으로 경로를 설정합니다.\n",
    "        #보통 랩탑에는 딥러닝 연산이 가능한 gpu가 없어,\n",
    "        #기본으로 cpu 환경에서 학습을 수행합니다.\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        #optimizer의 미분값을 초기화합니다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #이미지를 모델에 넣어 예측값을 출력합니다.\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        #예측값과 실제값의 loss를 구합니다.\n",
    "        batch_loss = loss_function(outputs, targets)\n",
    "        \n",
    "        #loss를 저장합니다.\n",
    "        #batch_loss가 Tensor이므로 .item()을 써서\n",
    "        #값만 빼옵니다.\n",
    "        losses.update(batch_loss.item())\n",
    "        \n",
    "        #확률이 가장 높은 숫자를 선택합니다.\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        #accuracy를 구합니다.\n",
    "        batch_accuracy = preds.eq(targets).sum().item() / inputs.size(0)\n",
    "        #accuracy를 업데이트합니다.\n",
    "        accuracy.update(batch_accuracy)\n",
    "        \n",
    "        #미분값(gradient)를 구합니다.\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        #모델의 파라미터를 업데이트합니다.\n",
    "        optimizer.step()\n",
    "        \n",
    "    #Epoch이 끝나면 loss와 accuracy의 평균값을 출력합니다.\n",
    "    print('[Epoch: {0:2d}]\\t'\n",
    "          'Loss {losses.avg:.4f}\\t'\n",
    "          'Acc {accuracy.avg:.4f}\\t'.format(epoch, losses=losses, accuracy=accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 함수 만들기\n",
    "파라미터 최적화에 사용되지 않은 Test 데이터셋을 사용해서 한 에폭이 끝날때마다 모델 성능을 평가하는 함수를 만들어봅시다.\n",
    "\n",
    "위에서 작성한 train 함수와 매우 유사하지만, 다음과 같은 차이점이 있습니다.\n",
    "\n",
    "1) 모델이 eval모드임을 지정해줘야 합니다.   \n",
    "  - model.train() => model.eval()\n",
    "  \n",
    "2) 파라미터를 업데이트하지 않으므로, 다음과 같은 내용이 필요없습니다.\n",
    "  - 미분값을 초기화하거나 업데이트하지않습니다.\n",
    "  - optimizer가 필요 없습니다.\n",
    "  \n",
    "위 명세를 바탕으로 evaluate 함수를 아래에 작성해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    pass\n",
    "    #TODO\n",
    "    #train 함수를 참고로 하여 evaluate 함수를 작성해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 모델을 돌릴텐데, 매번 같은 데이터를 사용하도록\n",
    "# 데이터셋을 가져오는 함수를 만듭니다.\n",
    "def initialize_dataset():\n",
    "    train_dataset = vdatasets.MNIST(root=\"data\", train=True, transform=transform, download=True)\n",
    "    test_dataset = vdatasets.MNIST(root=\"data\", train=False, transform=transform, download=True)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 초기화합니다.\n",
    "train_loader, test_loader = initialize_dataset()\n",
    "\n",
    "# 모델을 지정합니다. 기본 모델인 SimpleDNN으로 해보겠습니다.\n",
    "model = SimpleDNN()    \n",
    "\n",
    "# loss 함수와 optimizer를 지정합니다.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습을 5에폭 돌리겠습니다.\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # 학습을 수행합니다.\n",
    "    train(train_loader, model, loss_function, optimizer, epoch)\n",
    "    \n",
    "    # 검증을 수행합니다.\n",
    "    evaluate(test_loader, model, loss_function, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해봅시다!\n",
    "SimpleDNN으로도 높은 accuracy가 나옵니다. 와...그럼 아까 만들었던 더 복잡한 DNN으로는 어떤 결과가 나올까요? 위 코드를 참조해서 DNN의 결과를 돌려봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO DNN으로 모델을 만들고, Epoch을 5번 돌려봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 만들어보기\n",
    "- CNN은 필터(커널)을 사용해서 픽셀의 상하좌우, 채널간 관계를 학습하는 방식으로 이미지 처리에 뛰어난 성능을 보입니다.\n",
    "- 따라서 이전 DNN 모델처럼 입력 이미지를 `.view()`함수를 써서 변환할 필요가 없습니다.\n",
    "- 이번에는 다음과 같은 방식으로 모델을 만들어봅시다.\n",
    "  - input > conv1 > relu > pool > conv2 > relu > pool > flatten > fc1 > fc2 \n",
    "  - conv1의 입력채널은 1 (그레이스케일) 출력채널은 32, 필터 사이즈는 3x3으로 합니다.\n",
    "  - pool은 모두 kernel_size=2, stride=2로 합니다.\n",
    "  - conv2의 입력 채널은 32, 출력 채널은 64, 필터 사이즈는 3x3으로 합니다.\n",
    "  - 두번째 풀링이 끝나면 (배치사이즈, -1)로 flatten을 수행합니다.\n",
    "  - fc1의 입력 뉴런 수는 1600, 출력 뉴런수는 1024로 합니다.\n",
    "  - fc2의 입력 뉴런 수는 1024, 출력 뉴런수는 10으로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CNN 만들기\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        #TODO: conv2\n",
    "        self.conv2 = None\n",
    "        self.fc1 = nn.Linear(1600, 1024)\n",
    "        \n",
    "        #TODO: fc2\n",
    "        self.fc2 = None\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # 1st conv \n",
    "        x = self.conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #TODO: 2nd conv\n",
    "        x = None #conv2\n",
    "        x = None #ReLU\n",
    "        x = None #pool\n",
    "        \n",
    "        x = x.view(inputs.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 초기화합니다.\n",
    "train_loader, test_loader = initialize_dataset()\n",
    "\n",
    "# 모델을 지정합니다. 기본 모델인 SimpleDNN으로 해보겠습니다.\n",
    "model = CNN()    \n",
    "\n",
    "# loss 함수와 optimizer를 지정합니다.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습을 5에폭 돌리겠습니다.\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # 학습을 수행합니다.\n",
    "    train(train_loader, model, loss_function, optimizer, epoch)\n",
    "    \n",
    "    # 검증을 수행합니다.\n",
    "    evaluate(test_loader, model, loss_function, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장하기\n",
    "PyTorch에서 권장하는 방식은 모델의 파라미터만 저장하는 것입니다.\n",
    "https://pytorch.org/docs/master/notes/serialization.html#recommend-saving-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best_model.pth.tar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기\n",
    "클래스를 사용해 새로운 모델 인스턴스를 생성한다음,\n",
    "`torch.load` 함수와 `load_state_dict` 함수를 사용해서 파라미터를 읽어들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cnn = CNN()\n",
    "new_cnn.load_state_dict(torch.load(\"best_model.pth.tar\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 새로운 데이터 넣어보기\n",
    "자, 이제 새로운 데이터를 한번 넣어볼까요?\n",
    "https://sketch.io/sketchpad/ 에서 나만의 숫자 글씨를 써본다음,\n",
    "숫자가 한가운데 오도록 crop하고 다운로드합니다.\n",
    "그리고 주피터 노트북에서 읽을 수 있도록, 도커 컨테이터와 연결된 디렉토리에 집어넣습니다.\n",
    "이 과정이 귀찮다면 제가 쓴 숫자를 읽어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제가 쓴 숫자 2입니다.\n",
    "my_image = PIL.Image.open(\"img/mnist_1.png\").convert(\"L\")\n",
    "my_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 predict함수를 만들었습니다.\n",
    "def predict(model, img):\n",
    "    model.eval()\n",
    "    \n",
    "    # 맨위에서 설정한 transform 파이프라인 함수입니다.\n",
    "    # PIL 이미지를 28x28 사이즈로 바꾸고 숫자로 변환합니다.\n",
    "    my_image_tensor = transform(img)\n",
    "    \n",
    "    # 위에서는 batch_size가 64였는데, 여기는 1개라서\n",
    "    # 배치 차원이 없습니다. 0번째 차원을 추가해줍니다.\n",
    "    tensor = my_image_tensor.unsqueeze(0)\n",
    "    \n",
    "    # 모델이 무슨 숫자로 읽었는지 출력합니다.\n",
    "    print(model(tensor).argmax(dim=1).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(new_cnn, my_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 성공했습니다!\n",
    "제가 오늘 준비한 내용은 여기까지입니다. 짧은 시간 들으시느라 고생많으셨습니다.\n",
    "간단한 DNN, CNN 모델을 만들어보았는데요, 여러 하이퍼파라미터를 변형해보시면 또 재미있는 결과를 얻으실 수 있을 것 같습니다.\n",
    "문제가 생기면 언제든 도커 이미지로 다시 컨테이너를 생성하시면 원본 주피터 노트북을 얻으실 수 있을 겁니다.\n",
    "세션 내용 관련해서 궁금한 점이 있으시면 언제든 황준식[junsik.whang@nexon.co.kr]로 문의주십시오-\n",
    "\n",
    "또 딥러닝 관련해서 더 공부하시려면 다음과 같은 강좌를 추천합니다.\n",
    "- Coursera.org https://www.coursera.org/learn/neural-networks-deep-learning/home/welcome\n",
    "- Sirag Raval https://www.youtube.com/results?search_query=siraj+raval\n",
    "\n",
    "감사합니다!\n",
    "\n",
    "## E.O.D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손글씨 데이터셋 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.train_labels.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        \n",
    "        #TODO\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        \n",
    "        self.last_layer = nn.Linear(32, 10)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "         \n",
    "    def forward(self, inputs):\n",
    "        x = inputs.view(-1, 784)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        #TODO\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.last_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(loader, model, loss_function, epoch):\n",
    "    losses = AverageMeter()\n",
    "    accuracy = AverageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        batch_loss = loss_function(outputs, targets)\n",
    "        \n",
    "        losses.update(batch_loss.item())\n",
    "        \n",
    "        preds = outputs.argmax(dim=1)\n",
    "        batch_accuracy = preds.eq(targets).sum().item() / inputs.size(0)\n",
    "        accuracy.update(batch_accuracy)\n",
    "        \n",
    "    print('[Val Epoch: {0:2d}]\\t'\n",
    "          'Loss {losses.avg:.4f}\\t'\n",
    "          'Acc {accuracy.avg:.4f}\\t'.format(epoch, losses=losses, accuracy=accuracy))\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 초기화합니다.\n",
    "train_loader, test_loader = initialize_dataset()\n",
    "\n",
    "# 모델을 지정합니다. 기본 모델인 SimpleDNN으로 해보겠습니다.\n",
    "model = DNN()    \n",
    "\n",
    "# loss 함수와 optimizer를 지정합니다.\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 학습을 5에폭 돌리겠습니다.\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    # 학습을 수행합니다.\n",
    "    train(train_loader, model, loss_function, optimizer, epoch)\n",
    "    \n",
    "    # 검증을 수행합니다.\n",
    "    evaluate(test_loader, model, loss_function, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: CNN 만들기\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3)\n",
    "        self.fc1 = nn.Linear(1600, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # 1st conv \n",
    "        x = self.conv1(inputs)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        #TODO: 2nd conv\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(inputs.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
